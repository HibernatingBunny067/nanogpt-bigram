{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9x4xCqy7HTDg"
   },
   "source": [
    "# Mounting this notebook to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1754212584500,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "UGYXBs-uGJ0X"
   },
   "outputs": [],
   "source": [
    "# import os,sys\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import torch\n",
    "# root = r'/content/drive/MyDrive/Colab Notebooks/transformer/NanoGPT'\n",
    "# sys.path.append(root)\n",
    "# os.chdir(root)\n",
    "\n",
    "!git clone https://github.com/HibernatingBunny067/nanogpt-bigram\n",
    "%cd nanogpt-bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOmNatmmIwTF"
   },
   "source": [
    "# Downloading the Tiny-Shakespeare Dataset and Making a casual vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1754210963469,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "k6UMB_6mHQXP",
    "outputId": "a0cd7d4d-606b-4421-f057-d8b3dfdb3ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-03 08:49:22--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2025-08-03 08:49:23 (16.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1754211021043,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "F5We9qr7Hwy7",
    "outputId": "3115220e-810c-4ba7-be2f-3755fa082ce0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## opening and reading the file\n",
    "with open(os.path.join(root,'input.txt'),'r') as f:\n",
    "  text = f.read()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1754211045279,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "NPIK-iPzH-Ho",
    "outputId": "8939c5ff-f84a-4b8a-fbb4-841968f8d5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text downloaded: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of the text downloaded: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1754211109264,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "xzBGWqZlIE0Z",
    "outputId": "ae8b6a91-b005-4d75-e3a2-d5fe661cf60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# checking the dataset\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1754211158646,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "cOONwFYAIOts",
    "outputId": "b8b12794-ab51-4eb9-a92d-ecdfdad05e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "## making a simple vocabulary\n",
    "chars = sorted(list(set(text))) # set get rids of the duplicated character, list gives it order and sorted makes is sorted using ASCII\n",
    "vocab_size = len(chars)\n",
    "print(' '.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-nlb07TI2Ez"
   },
   "source": [
    "## Tokenizer\n",
    "- most basic character level tokenizer\n",
    "- two functions, encoder which takes a string and decoder which takes in a list of indexes and returns a string\n",
    "- there is a trade off which every tokenizer faces, this very basic iteration generates very long sequencse (same length as the number of characters in a string). Whereas in modern applications we prefer sublength tokenizer which have large vocabulary dictionaries (or sets) and produce small sequences\n",
    "- but for this project we stick to the most basic version for learning purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1754211494460,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "sCDS4E-pIgjN"
   },
   "outputs": [],
   "source": [
    "word2idx = {ch:i for i,ch in enumerate(chars)} #key is character and value is index - query\n",
    "idx2word = {i:ch for i,ch in enumerate(chars)}# key is index and value is character  - query\n",
    "\n",
    "def encoder(str):\n",
    "  return [word2idx.get(s) for s in str]\n",
    "def decoder(idx):\n",
    "  return [''.join(idx2word.get(i)for i in idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1754211528150,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "1ZHdZ4W6JeFO",
    "outputId": "650a7110-5f53-4381-c883-6bb0b49cc0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 39, 56, 47, 49, 43, 57, 46]\n",
      "['harikesh']\n",
      "[32, 46, 47, 57, 1, 44, 43, 43, 50, 57, 1, 45, 53, 53, 42, 1, 2, 2]\n",
      "['This feels good !!']\n"
     ]
    }
   ],
   "source": [
    "print(encoder('harikesh'))\n",
    "print(decoder(encoder('harikesh'))) #this seems to work\n",
    "\n",
    "print(encoder('This feels good !!'))\n",
    "print(decoder(encoder('This feels good !!')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvmtPI41LHsR"
   },
   "source": [
    "### Tokenize and Split the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1754211884156,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "X7aMsV7QJgdW",
    "outputId": "fe8ffa1c-b673-446e-d958-5b24744ca555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encoder(text),dtype=torch.long)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1754211924216,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "vUt4keskLXGB",
    "outputId": "b2264806-e3a8-4c6b-d366-3f75f686fb20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#some description of the data tensor\n",
    "print(data.shape,data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754211976619,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "b894a2w-Lbd1"
   },
   "outputs": [],
   "source": [
    "## spliting the data for early stopping and generalization check\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZTl5GQVL2AA"
   },
   "source": [
    "# Training the transformer\n",
    "- in practice we don't train transformers on whole of the train sequence, but we sample random chunks of predefined lengths\n",
    "- called chunk_size (for this work flow, I choose `chunk_size = 8 `to not face the computation overload on Colab GPUs)\n",
    "  ## how to use a chunk to train sub-sequences ?\n",
    "  - when using a chunk sized sequence, it actually contains chunk number of sub sequences which can be levearaged to train the network\n",
    "  - for ex: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) in this code\n",
    "    * for input 18 -> 47\n",
    "    * for input 18,47 -> 56\n",
    "    * for input 18,47,56 -> 58 and so on for the (chunk-1)th element sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1754214168033,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "PolneJUQL4y0",
    "outputId": "7afcb043-f28e-4130-cb3d-bfc427aa7edd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1754212455771,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "0y0qwzJBNE9l",
    "outputId": "d02a2dff-6595-4edc-f66f-421afb857833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is 47\n",
      "when input is tensor([18, 47]) the target is 56\n",
      "when input is tensor([18, 47, 56]) the target is 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "# code to demonstrate the subsequences present in a sequence\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "  context = x[:t+1] ##alias for attention\n",
    "  target = y[t] # alias for the prediction at each time step\n",
    "  print(f'when input is {context} the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1754212972440,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "8jL8Ml2iNVWZ",
    "outputId": "296a6866-9b22-4f90-fe22-f09c1dfaf7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "from transformer import batched_sampling\n",
    "\n",
    "obj1 = batched_sampling(train_data,val_data)\n",
    "xb,yb = obj1.get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets: ')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcPKzL_1Q3Ls"
   },
   "source": [
    "## BiGram Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1754221072323,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "UeQx3_bpPbW-"
   },
   "outputs": [],
   "source": [
    "from bigram import BigramModel\n",
    "# bi = BigramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1754221073401,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "Humn5pZCtpAh"
   },
   "outputs": [],
   "source": [
    "bi = BigramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1754221112763,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "KObkZn2fQ_Ne",
    "outputId": "dd08605d-9fec-4f6b-c550-b020f4a78832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65]) tensor(4.1797, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits,loss = bi(xb,yb)\n",
    "print(logits.shape,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1754214538822,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "Qy5CfvTJURM7",
    "outputId": "05c9f6d1-b1c3-429c-bc30-652593616c95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' lKgDga:e3o,3j,cER3MbvkZ$VOR JWudGJ.dL-DQEoEcOhLtaD']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "idx = torch.zeros((1,1),dtype=torch.long)\n",
    "decoder(bi.generate(idx,max_len=50)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1754221117511,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "br_7O6OiVSUD"
   },
   "outputs": [],
   "source": [
    "#training the model\n",
    "optimizer = torch.optim.AdamW(bi.parameters(),lr=1e-3) # higher learning rate for small network\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26337,
     "status": "ok",
     "timestamp": 1754221183414,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "QN5TvLn-VuY1",
    "outputId": "d439d004-6054-4e1d-a3fc-fca8269a562d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.50921368598938\n"
     ]
    }
   ],
   "source": [
    "for steps in range(10000):\n",
    "  xb,yb = obj1.get_batch('train')\n",
    "\n",
    "  logits,loss = bi(xb,yb)\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1754221189785,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "JM36JnlrWTVp",
    "outputId": "05910a86-4c5d-4028-95eb-4a9f58123757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My klLu at whemesru mye,\n",
      "AD ot w'd ys rod sed, ta eadthe dyon nt, thave mite.\n",
      "OE NYat:\n",
      "E:\n",
      "I;\n",
      "Anssine es ofy 't you ar pioinverce.\n",
      "\n",
      "Bargann, be amat be agtuet yo fimenast am\n",
      "Ander irse inecaduy ho we say koucantteaexingdoingerod ped rknerdied ithe. 's hes nck's tceas on bugs PRa wigun,\n",
      "Canwe maclard hald ght h th mut I pelrl;\n",
      "Mimy by hakind, usn. I GRLe he theamay wis becous at lilllo ake mincous itu sire ngit has ithat thindens ors tune lakinocupant\n",
      "Borus cha sewingu to tionondisolout ff.\n",
      "\n",
      "Ha,n:\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1),dtype=torch.long)\n",
    "print(decoder(bi.generate(idx,max_len=500)[0].tolist())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvC5VWu3Xs46"
   },
   "source": [
    "## Attention - a mathematical trick\n",
    "- in attention, we essentially want all the tokens at time step 'T' to talk with all the tokens preceeding it till T-1 from 1\n",
    "- for the most naive approach we can give that context as the average of all the T-1 tokens\n",
    "  - for optimizing this, we use a lower triangular matrix, and multiply it with the entire prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1754215197459,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "doZfmBPfXwhd",
    "outputId": "23ac9b99-9fea-487f-c546-2067dbe9ed1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1754215673998,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "pI_WbRgqX6Dc"
   },
   "outputs": [],
   "source": [
    "# x[b,t] = mean(i <=t) x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "  for t in range(T):\n",
    "    xprev = x[b,:t+1]\n",
    "    xbow[b,t]=torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1754216070357,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "Ilh4UIn9Zukc",
    "outputId": "ea925953-81bb-4eac-ba87-996afbfa7b93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[8., 6.],\n",
      "        [5., 2.],\n",
      "        [4., 4.]])\n",
      "tensor([[8.0000, 6.0000],\n",
      "        [6.5000, 4.0000],\n",
      "        [5.6667, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a,1,keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c  = a@b\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754216258501,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "aPWUdz5XbPnH"
   },
   "outputs": [],
   "source": [
    "wei = torch.tril(torch.ones((T,T)))\n",
    "wei = wei / wei.sum(1,keepdim=True)\n",
    "xbow2 = wei@x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwMUiLkZm9sC"
   },
   "source": [
    "## Self Attention\n",
    "-  attention is a communication mechanism\n",
    "  - examples don't talk to each other across batch, they only do to the blocks or chunks they belong to\n",
    "  - for decoder block, we don't want future blocks to communicate with the past one\n",
    "    - for encoder we don't do the mask\n",
    "- similar to a directed graph, where each ith node points to all the (i-1)th node and itself\n",
    "- it is permutation invariant, have no notion of 'space'\n",
    "  - this is very different from something like convolution, which has an positional invariance\n",
    "  \n",
    "### what is self attention and cross attention ??\n",
    "-  when keys, queries and values come form the same source (alignment inside a sequence) is called Self-Attention\n",
    "- when keys and values comes from a separate set of nodes (originally used in \"attention is all you need\" paper - 2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1754219273383,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "nHo-17vYm_VG",
    "outputId": "6c360640-91dc-468f-bd3d-4de215aca9d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.rand(B,T,C)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei =wei.masked_fill(tril==0,float('-inf')) ## exclusive to decoder\n",
    "wei = F.softmax(wei,dim=-1)\n",
    "out = wei@x\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1754220786373,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "n1mgyMpknafw",
    "outputId": "188119fc-09c0-4356-a280-b07cda6ec98c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8]), torch.Size([4, 8, 16]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C,head_size,bias=False)\n",
    "query = nn.Linear(C,head_size,bias = False)\n",
    "value = nn.Linear(C,head_size,bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "v  = value(x)\n",
    "wei =( q @ k.transpose(-2,-1) )*head_size**-0.5# (B,T,16) @ (B,16,T) --> (B,T,T)\n",
    "## sqrt division to prevent the variance at initialization\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril==0,float('-inf'))\n",
    "wei = F.softmax(wei,dim=-1) # now the weights are dependent on the data not simply averaged over all the T-1 tokens\n",
    "out = wei@v\n",
    "wei.shape,out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1754220291701,
     "user": {
      "displayName": "Harikesh Pratap Verma",
      "userId": "09787658353162672543"
     },
     "user_tz": -330
    },
    "id": "vg9VwYt5ocrz",
    "outputId": "a5250c7a-b459-41ed-ee06-83d98fec2dd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4925, 0.5075, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3390, 0.3478, 0.3132, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2545, 0.2595, 0.2503, 0.2357, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2010, 0.2097, 0.2080, 0.1846, 0.1967, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1629, 0.1737, 0.1654, 0.1540, 0.1669, 0.1771, 0.0000, 0.0000],\n",
       "        [0.1425, 0.1502, 0.1403, 0.1241, 0.1342, 0.1645, 0.1442, 0.0000],\n",
       "        [0.1300, 0.1311, 0.1230, 0.1173, 0.1215, 0.1324, 0.1134, 0.1313]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iters = 5000\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embed = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbigram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BigramModel\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m BigramModel(\u001b[43mvocab_size\u001b[49m,device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "from bigram import BigramModel\n",
    "model = BigramModel(vocab_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOeih5uU+ZAUiD3992crdhd",
   "collapsed_sections": [
    "9x4xCqy7HTDg",
    "BOmNatmmIwTF",
    "XvC5VWu3Xs46"
   ],
   "mount_file_id": "1LinyMGCtLwf31rMlqGyKJAAird_XadIB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
